{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 05卷积神经网络\n",
    "___"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 配置设备\n",
    "device = torch.device('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 设置超参数\n",
    "num_epochs = 5\n",
    "num_classes = 10 \n",
    "batch_size = 100\n",
    "learning_rate = 0.001\n",
    "# MNIST数据集\n",
    "train_dataset = torchvision.datasets.MNIST(root='/home/wangye/data',\n",
    "                                          train=True,\n",
    "                                          transform=transforms.ToTensor(),\n",
    "                                          download=True)\n",
    "test_dataset = torchvision.datasets.MNIST(root='/home/wangye/data',\n",
    "                                         train=False,\n",
    "                                         transform=transforms.ToTensor())\n",
    "# 数据加载\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_dataset,\n",
    "                                          batch_size=batch_size,\n",
    "                                          shuffle=True)\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(dataset=test_dataset,\n",
    "                                         batch_size=batch_size,\n",
    "                                         shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义包含两个卷积层的卷积神经网络\n",
    "class ConvNet(nn.Module):\n",
    "    def __init__(self,num_classes=10):\n",
    "        super(ConvNet,self).__init__()\n",
    "        self.layer1 = nn.Sequential(\n",
    "            nn.Conv2d(1,16,kernel_size=5,stride=1,padding=2),\n",
    "            nn.BatchNorm2d(16),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2,stride=2)\n",
    "        )\n",
    "        self.layer2 = nn.Sequential(\n",
    "            nn.Conv2d(16,32,kernel_size=5,stride=1,padding=2),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2,stride=2)\n",
    "        )\n",
    "        self.fc = nn.Linear(7*7*32,num_classes)\n",
    "    def forward(self,x):\n",
    "        out = self.layer1(x)\n",
    "        out = self.layer2(out)\n",
    "#         print(out.shape)\n",
    "        out = out.reshape(out.size(0),-1)\n",
    "        out = self.fc(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 上述代码讲解：\n",
    "1. class torch.nn.Sequential(* args)\n",
    "    * 这是一个时序的容器，可以按照我们传入的顺序添加进去，帮助我们快速搭建神经网络\n",
    "2. class torch.nn.Conv2d(in_channels, out_channels, kernel_size, stride=1, padding=0, dilation=1, groups=1, bias=True):\n",
    "    * 二维卷积层，输入尺寸为（N,C_in,H_in,W_in）输出尺寸为(N,C_out,H_out,W_out)\n",
    "    * 参数讲解：\n",
    "        * in_channels:输入的通道数,比如说灰色图片通道为1，彩色为3（RGB）\n",
    "        * out_channels:输出的通道数，输出的通道数跟卷积核的数量有关，或者说等于卷积核的数量。\n",
    "        * kernel_size:卷积核大小\n",
    "        * stride:表示步长\n",
    "        * padding:为了保持输入和输出相同，补0的层数\n",
    "            * 根据公式$1+2*2-5+1=1$可见padding设置为2刚好满足要求\n",
    "3. class torch.nn.BatchNorm2d(num_features, eps=1e-05, momentum=0.1, affine=True)：\n",
    "    * 对输入的数据进行标准化处理，现在不需要深究，以后会展开讲\n",
    "    * 参数讲解：\n",
    "        * num_features:期望输入的特征数\n",
    "        * 其他参数默认设置就好，不作讲解\n",
    "4. class torch.nn.MaxPool2d(kernel_size, stride=None, padding=0, dilation=1, return_indices=False, ceil_mode=False)：\n",
    "    * 对输入的数据做二维的最大池化操作\n",
    "    * 参数讲解：\n",
    "         * kernel_size: max pooling的窗口大小\n",
    "         * stride:窗口移动的步长\n",
    "         * 其余参数可以参考文档，此处不展开讲解\n",
    "         \n",
    "___\n",
    "         "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 神经网络的输入输出shape解释：\n",
    "其实非常简单，只要熟悉卷积核运算后的输出shape1公式，和max池化后的输出shape2公式，问题便迎刃而解\n",
    "1. shape_1公式：\n",
    "    $W_{out} = \\frac{W_{in}+2*P-F}{S}+1$\n",
    "2. shape_2公式：\n",
    "    $W_{out} =\\frac{W_{in}-F}{S}+1$\n",
    "3. 参数：\n",
    "    * W即为输入的宽，长也一样\n",
    "    * P 为Padding的长度\n",
    "    * F 为滤波器的大小\n",
    "    * S 为步长\n",
    "对于本网络的具体推导，以图片的形式展示出来：<br>\n",
    "\n",
    "![shape推导](https://github.com/wangye8899/Pytorch/blob/master/IMAGES/gaitubao_13254023_-90.jpg?raw=true)\n",
    "___"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 实例化网络\n",
    "model = ConvNet(num_classes).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义损失函数和优化器\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(),lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch[1/5],Step[100/600],Loss:0.2065\n",
      "Epoch[1/5],Step[200/600],Loss:0.0436\n",
      "Epoch[1/5],Step[300/600],Loss:0.1447\n",
      "Epoch[1/5],Step[400/600],Loss:0.0394\n",
      "Epoch[1/5],Step[500/600],Loss:0.0531\n",
      "Epoch[1/5],Step[600/600],Loss:0.0421\n",
      "Epoch[2/5],Step[100/600],Loss:0.0518\n",
      "Epoch[2/5],Step[200/600],Loss:0.0249\n",
      "Epoch[2/5],Step[300/600],Loss:0.0132\n",
      "Epoch[2/5],Step[400/600],Loss:0.0658\n",
      "Epoch[2/5],Step[500/600],Loss:0.0299\n",
      "Epoch[2/5],Step[600/600],Loss:0.0705\n",
      "Epoch[3/5],Step[100/600],Loss:0.0104\n",
      "Epoch[3/5],Step[200/600],Loss:0.0177\n",
      "Epoch[3/5],Step[300/600],Loss:0.0112\n",
      "Epoch[3/5],Step[400/600],Loss:0.0203\n",
      "Epoch[3/5],Step[500/600],Loss:0.0404\n",
      "Epoch[3/5],Step[600/600],Loss:0.0737\n",
      "Epoch[4/5],Step[100/600],Loss:0.0439\n",
      "Epoch[4/5],Step[200/600],Loss:0.0209\n",
      "Epoch[4/5],Step[300/600],Loss:0.0264\n",
      "Epoch[4/5],Step[400/600],Loss:0.0179\n",
      "Epoch[4/5],Step[500/600],Loss:0.0199\n",
      "Epoch[4/5],Step[600/600],Loss:0.0138\n",
      "Epoch[5/5],Step[100/600],Loss:0.0346\n",
      "Epoch[5/5],Step[200/600],Loss:0.0044\n",
      "Epoch[5/5],Step[300/600],Loss:0.0199\n",
      "Epoch[5/5],Step[400/600],Loss:0.0768\n",
      "Epoch[5/5],Step[500/600],Loss:0.1100\n",
      "Epoch[5/5],Step[600/600],Loss:0.0377\n"
     ]
    }
   ],
   "source": [
    "# 训练模型\n",
    "total_step = len(train_loader)\n",
    "for epoch in range(num_epochs):\n",
    "    for i ,(images,labels) in enumerate(train_loader):\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "#         前向传播\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs,labels)\n",
    "#         反向传播，更新参数\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if (i+1)%100 == 0:\n",
    "            print('Epoch[{}/{}],Step[{}/{}],Loss:{:.4f}'.format(epoch+1,num_epochs,i+1,\n",
    "                                                               total_step,\n",
    "                                                               loss.item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000条测试数据的准确率为：98.9\n",
      "10000\n",
      "9890\n"
     ]
    }
   ],
   "source": [
    "# 测试模型\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    correct = 0\n",
    "    total  = 0\n",
    "    for images , labels in test_loader:\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        outputs = model(images)\n",
    "        _,predicted = torch.max(outputs.data,1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted==labels).sum().item()\n",
    "    print('10000条测试数据的准确率为：{}'.format(100*correct/total))\n",
    "torch.save(model.state_dict(),'model.ckpt')\n",
    "print(total)\n",
    "print(correct)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
